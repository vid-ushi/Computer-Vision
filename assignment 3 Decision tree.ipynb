{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PVtLpWTEFuyX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZ5__FtfKdjr"
   },
   "source": [
    "# Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PaXB_NQdHp4d"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    [30, 'high', 'no', 'fair', 'no'],\n",
    "    [30, 'high', 'no', 'excellent', 'no'],\n",
    "    [31, 'medium', 'no', 'fair', 'yes'],\n",
    "    [40, 'low', 'no', 'fair', 'yes'],\n",
    "    [40, 'low', 'yes', 'fair', 'yes'],\n",
    "    [40, 'low', 'yes', 'excellent', 'no'],\n",
    "    [31, 'medium', 'yes', 'excellent', 'yes'],\n",
    "    [30, 'high', 'no', 'fair', 'no'],\n",
    "    [30, 'medium', 'yes', 'fair', 'yes'],\n",
    "    [31, 'medium', 'yes', 'excellent', 'yes'],\n",
    "    [31, 'high', 'no', 'excellent', 'yes'],\n",
    "    [40, 'medium', 'no', 'fair', 'yes'],\n",
    "    [40, 'high', 'yes', 'fair', 'yes'],\n",
    "    [31, 'medium', 'no', 'excellent', 'no']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1Kl8ZgXKxyX"
   },
   "source": [
    "# Convert the dataset into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ICuvT9JnKKRY"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['age', 'income', 'student', 'credit_rating', 'buys_computer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60D_YrYDK3YA"
   },
   "source": [
    "# Define the features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DVvlD6F-KT5E"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['buys_computer'])\n",
    "y = df['buys_computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqIp-1VcK-Zl"
   },
   "source": [
    "# Define a class for the decision tree node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LU_IML4sKZqU"
   },
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature=None, value=None, left=None, right=None, target_class=None):\n",
    "        self.feature = feature  # Index of feature to split on\n",
    "        self.value = value  # Value of the feature\n",
    "        self.left = left  # Left subtree\n",
    "        self.right = right  # Right subtree\n",
    "        self.target_class = target_class  # Target class if the node is a leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLoBBkynLCse"
   },
   "source": [
    "# Define a function to calculate entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UBPKiJ66LKUo"
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(y):\n",
    "    class_counts = y.value_counts()\n",
    "    entropy = 0\n",
    "    for count in class_counts:\n",
    "        probability = count / len(y)\n",
    "        entropy -= probability * math.log2(probability)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKGPyDWYLhpX"
   },
   "source": [
    "# Define a function to calculate information gain for a particular feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FELT0wkKLtYN"
   },
   "outputs": [],
   "source": [
    "def calculate_information_gain(X, y, feature, split_value):\n",
    "    total_entropy = calculate_entropy(y)\n",
    "\n",
    "    # Split the dataset based on the feature and value\n",
    "    left_indices = X[feature] <= split_value\n",
    "    right_indices = X[feature] > split_value\n",
    "    left_entropy = calculate_entropy(y[left_indices])\n",
    "    right_entropy = calculate_entropy(y[right_indices])\n",
    "\n",
    "    # Calculate the information gain\n",
    "    left_weight = sum(left_indices) / len(y)\n",
    "    right_weight = sum(right_indices) / len(y)\n",
    "    information_gain = total_entropy - (left_weight * left_entropy + right_weight * right_entropy)\n",
    "\n",
    "    return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKzhAzx_L1Cq"
   },
   "source": [
    "# Define a function to build the decision tree recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KA_JWwiML3V1"
   },
   "outputs": [],
   "source": [
    "def build_decision_tree(X, y):\n",
    "    if len(set(y)) == 1:  # If all samples have the same class\n",
    "        return DecisionTreeNode(target_class=y.iloc[0])\n",
    "\n",
    "    if len(X.columns) == 0:  # If there are no features left to split on\n",
    "        return DecisionTreeNode(target_class=y.mode()[0])\n",
    "\n",
    "    best_information_gain = 0\n",
    "    best_feature = None\n",
    "    best_split_value = None\n",
    "\n",
    "    # Find the best feature and split value\n",
    "    for feature in X.columns:\n",
    "        unique_values = X[feature].unique()\n",
    "        for value in unique_values:\n",
    "            information_gain = calculate_information_gain(X, y, feature, value)\n",
    "            if information_gain > best_information_gain:\n",
    "                best_information_gain = information_gain\n",
    "                best_feature = feature\n",
    "                best_split_value = value\n",
    "\n",
    "    # Split the dataset based on the best feature and split value\n",
    "    left_indices = X[best_feature] <= best_split_value\n",
    "    right_indices = X[best_feature] > best_split_value\n",
    "    left_subtree = build_decision_tree(X[left_indices], y[left_indices])\n",
    "    right_subtree = build_decision_tree(X[right_indices], y[right_indices])\n",
    "\n",
    "    return DecisionTreeNode(feature=best_feature, value=best_split_value, left=left_subtree, right=right_subtree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkFpqueBPDX5"
   },
   "source": [
    "# Define a function to make predictions using the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2R4Zm3NfPEZ6"
   },
   "outputs": [],
   "source": [
    "def predict(tree, sample):\n",
    "    if tree.target_class is not None:\n",
    "        return tree.target_class\n",
    "    feature_index = X.columns.get_loc(tree.feature)\n",
    "    if sample[feature_index] <= tree.value:\n",
    "        return predict(tree.left, sample)\n",
    "    else:\n",
    "        return predict(tree.right, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjsxlRbcPLnt"
   },
   "source": [
    "# Build the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ih6Ti8J2PMwV"
   },
   "outputs": [],
   "source": [
    "decision_tree = build_decision_tree(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xX_s4jdPRbG"
   },
   "source": [
    "# Make predictions for new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUd3ZH8bPSzH",
    "outputId": "4c8829b0-fd0b-4d15-bd88-399e1c7d5f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sample [20, 'low', 'yes', 'excellent'], predicted class: yes\n",
      "For sample [30, 'high', 'no', 'fair'], predicted class: no\n",
      "For sample [40, 'medium', 'yes', 'fair'], predicted class: yes\n",
      "For sample [50, 'low', 'no', 'fair'], predicted class: yes\n",
      "For sample [25, 'high', 'yes', 'excellent'], predicted class: no\n",
      "For sample [35, 'medium', 'no', 'fair'], predicted class: yes\n",
      "For sample [45, 'low', 'yes', 'excellent'], predicted class: no\n",
      "For sample [55, 'high', 'no', 'fair'], predicted class: yes\n"
     ]
    }
   ],
   "source": [
    "data2 = [\n",
    "    [20, 'low', 'yes', 'excellent'],\n",
    "    [30, 'high', 'no', 'fair'],\n",
    "    [40, 'medium', 'yes', 'fair'],\n",
    "    [50, 'low', 'no', 'fair'],\n",
    "    [25, 'high', 'yes', 'excellent'],\n",
    "    [35, 'medium', 'no', 'fair'],\n",
    "    [45, 'low', 'yes', 'excellent'],\n",
    "    [55, 'high', 'no', 'fair'],\n",
    "]\n",
    "\n",
    "for sample in data2:\n",
    "    prediction = predict(decision_tree, sample)\n",
    "    print(f\"For sample {sample}, predicted class: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiMg7GA1PV6E"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
